% Encoding: UTF-8

@Manual{contextual,
  title        = {contextual: Simulating Contextual Multi-Armed Bandit Problems in R},
  author       = {van Emden, R. and Kaptein, M. and Postma, E.},
  organization = {Jheronimus Academy of Data Science},
  month        = jun,
  year         = {2018},
  journaltitle = {In preparation for submission to The Journal of Statistical Software},
}

@Article{Wilson2014,
  author    = {Wilson, Robert C and Geana, Andra and White, John M and Ludvig, Elliot A and Cohen, Jonathan D},
  title     = {Humans use directed and random exploration to solve the explore--exploit dilemma.},
  journal   = {Journal of Experimental Psychology: General},
  year      = {2014},
  volume    = {143},
  number    = {6},
  pages     = {2074},
  publisher = {American Psychological Association},
}

@Article{Whittle1979,
  author  = {Whittle, P},
  title   = {Discussion on:“Bandit processes and dynamic allocation indices”[JR Statist. Soc. B, 41, 148--177, 1979] by JC Gittins},
  journal = {J. Roy. Statist. Soc. Ser. B},
  year    = {1979},
  volume  = {41},
  pages   = {165},
}

@Article{Bubeck2012,
  author    = {Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and others},
  title     = {Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  journal   = {Foundations and Trends{\textregistered} in Machine Learning},
  year      = {2012},
  volume    = {5},
  number    = {1},
  pages     = {1--122},
  publisher = {Now Publishers, Inc.},
}

@InProceedings{Langford2008,
  author    = {Langford, John and Zhang, Tong},
  title     = {The epoch-greedy algorithm for multi-armed bandits with side information},
  booktitle = {Advances in neural information processing systems},
  year      = {2008},
  pages     = {817--824},
}

@InCollection{Tewari2017,
  author    = {Tewari, Ambuj and Murphy, Susan A},
  title     = {From ads to interventions: Contextual bandits in mobile health},
  booktitle = {Mobile Health},
  publisher = {Springer},
  year      = {2017},
  pages     = {495--517},
}

@Article{Wang2005a,
  author    = {Wang, Chih-Chun and Kulkarni, Sanjeev R and Poor, H Vincent},
  title     = {Arbitrary side observations in bandit problems},
  journal   = {Advances in Applied Mathematics},
  year      = {2005},
  volume    = {34},
  number    = {4},
  pages     = {903--938},
  publisher = {Elsevier},
}

@InProceedings{Lu2010,
  author    = {Lu, Tyler and P{\'a}l, D{\'a}vid and P{\'a}l, Martin},
  title     = {Contextual multi-armed bandits},
  booktitle = {Proceedings of the Thirteenth international conference on Artificial Intelligence and Statistics},
  year      = {2010},
  pages     = {485--492},
}

@Article{Kaelbling1996,
  author  = {Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  title   = {Reinforcement learning: A survey},
  journal = {Journal of artificial intelligence research},
  year    = {1996},
  volume  = {4},
  pages   = {237--285},
}

@Article{Abe2003,
  author    = {Abe, Naoki and Biermann, Alan W and Long, Philip M},
  title     = {Reinforcement learning with immediate rewards and linear hypotheses},
  journal   = {Algorithmica},
  year      = {2003},
  volume    = {37},
  number    = {4},
  pages     = {263--293},
  publisher = {Springer},
}

@InProceedings{Strehl2006,
  author       = {Strehl, Alexander L and Mesterharm, Chris and Littman, Michael L and Hirsh, Haym},
  title        = {Experience-efficient learning in associative bandit problems},
  booktitle    = {Proceedings of the 23rd international conference on Machine learning},
  year         = {2006},
  pages        = {889--896},
  organization = {ACM},
}

@Article{Sarkar1991,
  author    = {Sarkar, Jyotirmoy},
  title     = {One-armed bandit problems with covariates},
  journal   = {The Annals of Statistics},
  year      = {1991},
  pages     = {1978--2002},
  publisher = {JSTOR},
}

@Article{Lai1985,
  author    = {Lai, Tze Leung and Robbins, Herbert},
  title     = {Asymptotically efficient adaptive allocation rules},
  journal   = {Advances in applied mathematics},
  year      = {1985},
  volume    = {6},
  number    = {1},
  pages     = {4--22},
  publisher = {Academic Press},
}

@Article{Auer2002,
  author    = {Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
  title     = {Finite-time analysis of the multiarmed bandit problem},
  journal   = {Machine learning},
  year      = {2002},
  volume    = {47},
  number    = {2-3},
  pages     = {235--256},
  publisher = {Springer},
}

@InProceedings{Li2010,
  author       = {Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  title        = {A contextual-bandit approach to personalized news article recommendation},
  booktitle    = {Proceedings of the 19th international conference on World wide web},
  year         = {2010},
  pages        = {661--670},
  organization = {ACM},
}

@InProceedings{Tang2013,
  author       = {Tang, Liang and Rosales, Romer and Singh, Ajit and Agarwal, Deepak},
  title        = {Automatic ad format selection via contextual bandits},
  booktitle    = {Proceedings of the 22nd ACM international conference on Conference on information \& knowledge management},
  year         = {2013},
  pages        = {1587--1594},
  organization = {ACM},
}

@Misc{Langford2007,
  author   = {Langford, John and Li, Lihong and Strehl, Alex},
  title    = {Vowpal \{{W}\}abbit},
  year     = {2007},
  keywords = {cj-bib},
}

@Article{Kaptein2016,
  author     = {Kaptein, M. C. and Kruijswijk, J. M. A.},
  title      = {Streamingbandit: {A} platform for developing adaptive persuasive systems},
  journal    = {JSS},
  year       = {2016},
  file       = {Snapshot:http\://repository.ubn.ru.nl/bitstream/handle/2066/161901/161901.pdf:;Fulltext:http\://repository.ubn.ru.nl/bitstream/handle/2066/161901/161901.pdf:application/pdf},
  publisher  = {Salzburg: Center for Human-Computer Interaction, Department of Computer Science, University of Salzburg},
  shorttitle = {Streamingbandit},
}

@Electronic{striatum,
  author     = {NTUCSIE-CLLab},
  year       = {2018},
  title      = {striatum: {Contextual} bandit in python},
  url        = {https://github.com/ntucllab/striatum},
  copyright  = {BSD-2-Clause},
  shorttitle = {striatum},
  urldate    = {2018-07-31TZ},
}

@Misc{SMPyBandits,
  author       = {Lilian Besson},
  title        = {{SMPyBandits: an Open-Source Research Framework for Single and Multi-Players Multi-Arms Bandits (MAB) Algorithms in Python}},
  howpublished = {Online at: \url{github.com/SMPyBandits/SMPyBandits}},
  year         = {2018},
  note         = {Code at https://github.com/SMPyBandits/SMPyBandits/, documentation at https://smpybandits.github.io/},
  url          = {https://github.com/SMPyBandits/SMPyBandits/},
}

@Electronic{RCore,
  author       = {{R Core Team}},
  year         = {2018},
  title        = {R: A Language and Environment for Statistical Computing},
  language     = {English},
  organization = {R Foundation for Statistical Computing},
  address      = {Vienna, Austria},
  url          = {https://www.R-project.org},
}

@InProceedings{Li2011,
  author    = {Li, Lihong and Chu, Wei and Langford, John and Wang, Xuanhui},
  title     = {Unbiased {Offline} {Evaluation} of {Contextual}-bandit-based {News} {Article} {Recommendation} {Algorithms}},
  booktitle = {Proceedings of the {Fourth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
  year      = {2011},
  series    = {{WSDM} '11},
  pages     = {297--306},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Contextual bandit algorithms have become popular for online recommendation systems such as Digg, Yahoo! Buzz, and news recommendation in general. Offline evaluation of the effectiveness of new algorithms in these applications is critical for protecting online user experiences but very challenging due to their partial-label nature. Common practice is to create a simulator which simulates the online environment for the problem at hand and then run an algorithm against this simulator. However, creating simulator itself is often difficult and modeling bias is usually unavoidably introduced. In this paper, we introduce a replay methodology for contextual bandit algorithm evaluation. Different from simulator-based approaches, our method is completely data-driven and very easy to adapt to different applications. More importantly, our method can provide provably unbiased evaluations. Our empirical results on a large-scale news article recommendation dataset collected from Yahoo! Front Page conform well with our theoretical results. Furthermore, comparisons between our offline replay and online bucket evaluation of several contextual bandit algorithms show accuracy and effectiveness of our offline evaluation method.},
  doi       = {10.1145/1935826.1935878},
  file      = {ACM Full Text PDF:http\://dl.acm.org/ft_gateway.cfm?id=1935878&type=pdf:application/pdf},
  isbn      = {9781450304931},
  keywords  = {benchmark dataset, contextual bandit, multi-armed bandit, offline evaluation, recommendation},
  url       = {http://doi.acm.org/10.1145/1935826.1935878},
  urldate   = {2018-08-01TZ},
}

@InProceedings{Mousavi2016,
  author       = {Mousavi, Seyed Sajad and Schukat, Michael and Howley, Enda},
  title        = {Deep reinforcement learning: an overview},
  booktitle    = {Proceedings of SAI Intelligent Systems Conference},
  year         = {2016},
  pages        = {426--440},
  organization = {Springer},
}

@InProceedings{Seldin2011,
  author    = {Seldin, Yevgeny and Auer, Peter and Shawe-Taylor, John S and Ortner, Ronald and Laviolette, Fran{\c{c}}ois},
  title     = {PAC-Bayesian analysis of contextual bandits},
  booktitle = {Advances in neural information processing systems},
  year      = {2011},
  pages     = {1683--1691},
}

@Article{Li2017,
  author        = {Li, Yuxi},
  title         = {Deep reinforcement learning: An overview},
  journal       = {arXiv preprint arXiv:1701.07274},
  year          = {2017},
  __markedentry = {[robin:]},
}

@InProceedings{Agarwal2014,
  author        = {Agarwal, Alekh and Hsu, Daniel and Kale, Satyen and Langford, John and Li, Lihong and Schapire, Robert},
  title         = {Taming the monster: A fast and simple algorithm for contextual bandits},
  booktitle     = {International Conference on Machine Learning},
  year          = {2014},
  pages         = {1638--1646},
  __markedentry = {[robin:6]},
}

@Comment{jabref-meta: databaseType:bibtex;}
